// server.js  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import express from "express";
import cors    from "cors";
import dotenv  from "dotenv";
import OpenAI  from "openai";

dotenv.config();

const PORT   = process.env.PORT || 4000;
const APIKEY = process.env.OPENAI_API_KEY;

// fail fast if no key
if (!APIKEY) {
  console.error("âŒ  OPENAI_API_KEY not found in .env");
  process.exit(1);
}

const app    = express();
const openai = new OpenAI({ apiKey: APIKEY });

app.use(cors());
app.use(express.json());

// â”€â”€ helper: openai call with retry/back-off â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const MAX_RETRIES = 3;
async function chatWithRetry(payload, attempt = 0) {
  try {
    return await openai.chat.completions.create(payload);
  } catch (err) {
    // 429 can be rate-limit OR exhausted quota
    if (err.status === 429 && attempt < MAX_RETRIES) {
      const delay = 1000 * (attempt + 1); // 1s, 2s, 3s â€¦
      console.warn(`âš ï¸  OpenAI 429 â€“ retrying in ${delay} ms (attempt ${attempt + 1})`);
      await new Promise(r => setTimeout(r, delay));
      return chatWithRetry(payload, attempt + 1);
    }
    throw err; // re-throw after retries or other errors
  }
}

// â”€â”€ health-check so / shows something â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.get("/", (_, res) => {
  res.send("âœ… StudyPal backend is running");
});

// â”€â”€ chat endpoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.post("/api/chat", async (req, res) => {
  try {
    const { messages } = req.body;

    if (!Array.isArray(messages) || messages.length === 0) {
      return res.status(400).json({ error: "messages array required" });
    }

    const completion = await chatWithRetry({
      model: "gpt-3.5-turbo",
      messages,
      max_tokens: 512
    });

    const reply = completion.choices[0]?.message?.content?.trim() || "";
    console.log("ğŸ”„  OpenAI reply:", reply.slice(0, 80), "â€¦");

    res.json({ reply });
  } catch (err) {
    // Handle quota/rate-limit separately so the client knows to try later
    if (err.status === 429 || err.code === "insufficient_quota") {
      console.error("ğŸš§  OpenAI quota / rate limit hit:", err.message);
      return res.status(503).json({ error: "AI service is temporarily unavailable. Please try again later." });
    }

    console.error("ğŸ’¥  /api/chat error:", err);
    res.status(500).json({ error: "Internal server error." });
  }
});

// â”€â”€ start the server â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.listen(PORT, () => {
  console.log(`ğŸš€  API up on http://localhost:${PORT}`);
});
